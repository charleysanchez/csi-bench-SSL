training:
  epochs: 100
  patience: 20
  batch_size: 32

optimizer:
  name: adamw
  lr: 0.001
  weight_decay: 1e-5

scheduler:
  name: warmup_cosine
  warmup_epochs: 5
  min_lr_ratio: 0.0

model_params:
  win_len: 500
  feature_size: 232
